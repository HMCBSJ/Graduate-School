{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T06:02:38.130332Z",
     "start_time": "2019-06-08T06:02:38.114706Z"
    }
   },
   "source": [
    "# 主題: 電影評分預測\n",
    "本項目使用文本卷積神經網絡，並使用[`MovieLens`](https://grouplens.org/datasets/movielens/)數據集完成電影推薦的任務<br>\n",
    "![ex_screenshot](reco.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  組員 : \n",
    "* ChoiHyunMin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:51:28.609486Z",
     "start_time": "2019-06-08T12:51:28.578237Z"
    }
   },
   "source": [
    "### 主題 : \n",
    "* 使用DNN，Linear Regression及SVM 來比較 傳統機器學習方法與DNN預測頻分的精度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T11:12:52.885691Z",
     "start_time": "2019-06-08T11:12:52.870066Z"
    }
   },
   "source": [
    "### 介紹 :\n",
    "* 推薦系統在信息化日益發達的今天尤其重要，比如網上購物、網上買書、新聞頭條、社交網絡、音樂網站、電影資訊等，有用戶的地方就需要推薦。對擁有相同喜好，相同行為習慣的人群等信息進行個性化的內容推薦。<br>關鍵 : 使用三個模型及不同方法前處理。比較用什麼特征，或用什麼模型跟參數的時候 預測結果比較好。<br>\n",
    "\n",
    "* 若要猜測電影, 因爲每個人不可能都看數據裏面的4000個電影之後都打評分,這導致很低的準確率。 所以我是要猜測每個人對每個電影評分。若找到評分高的電影就推薦給他。所以這邊要研究每個人對每個電影的評分的精確。是否接近他真實評分。推薦給客人適合的電影是我要研究的future work。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 實作方法 : \n",
    " 1. 使用LR,SVM,DNN做出個性化推薦（圖片的方式去分析及訓練）\n",
    " 2. 比較state-of-art的方式DNN跟傳統方法LR,SVM來做出一些洞察<br>\n",
    "![ex_screenshot](moviedat.png)<br>\n",
    " 3. 比較時，使用MSE,MAE來比較<br><br>\n",
    "![ex_screenshot](mse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import該用到的套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T09:20:56.945669Z",
     "start_time": "2019-06-08T09:20:55.039418Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "from tensorflow.python.ops import math_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T09:20:59.883169Z",
     "start_time": "2019-06-08T09:20:59.039419Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras utilis function\n",
    "from keras import metrics\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import keras\n",
    "from keras.backend import set_session\n",
    "import tensorflow as tf\n",
    "import os\n",
    "def create_session(gpu_id='0', pp_mem_frac=None):\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_id # can multiple?\n",
    "    with tf.device('/gpu:' + gpu_id):\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        if pp_mem_frac is not None:\n",
    "            config.gpu_options.per_process_gpu_memory_fraction=pp_mem_frac\n",
    "        session = tf.Session(config = config)\n",
    "    return session\n",
    "\n",
    "gpu_id = '0'\n",
    "sess = create_session(gpu_id)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下載數據集\n",
    "運行下面代碼把[`數據集`](http://files.grouplens.org/datasets/movielens/ml-1m.zip)下載下來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T09:21:02.742543Z",
     "start_time": "2019-06-08T09:21:02.711294Z"
    }
   },
   "outputs": [],
   "source": [
    "#下載數據之後放在資料夾的程式碼\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import hashlib\n",
    "\n",
    "def _unzip(save_path, _, database_name, data_path):\n",
    "    print('Extracting {}...'.format(database_name))\n",
    "    with zipfile.ZipFile(save_path) as zf:\n",
    "        zf.extractall(data_path)\n",
    "\n",
    "def download_extract(database_name, data_path):\n",
    "    DATASET_ML1M = 'ml-1m'\n",
    "\n",
    "    if database_name == DATASET_ML1M:\n",
    "        url = 'http://files.grouplens.org/datasets/movielens/ml-1m.zip'\n",
    "        hash_code = 'c4d9eecfca2ab87c1945afe126590906'\n",
    "        extract_path = os.path.join(data_path, 'ml-1m')\n",
    "        save_path = os.path.join(data_path, 'ml-1m.zip')\n",
    "        extract_fn = _unzip\n",
    "\n",
    "    if os.path.exists(extract_path):\n",
    "        print('Found {} Data'.format(database_name))\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        with DLProgress(unit='B', unit_scale=True, miniters=1, desc='Downloading {}'.format(database_name)) as pbar:\n",
    "            urlretrieve(\n",
    "                url,\n",
    "                save_path,\n",
    "                pbar.hook)\n",
    "\n",
    "    assert hashlib.md5(open(save_path, 'rb').read()).hexdigest() == hash_code, \\\n",
    "        '{} file is corrupted.  Remove the file and try again.'.format(save_path)\n",
    "\n",
    "    os.makedirs(extract_path)\n",
    "    try:\n",
    "        extract_fn(save_path, extract_path, database_name, data_path)\n",
    "    except Exception as err:\n",
    "        shutil.rmtree(extract_path)  # Remove extraction folder if there is an error\n",
    "        raise err\n",
    "\n",
    "    print('Done.')\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 把資料度進來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T09:21:04.789454Z",
     "start_time": "2019-06-08T09:21:04.773889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found ml-1m Data\n"
     ]
    }
   ],
   "source": [
    "data_dir = './'\n",
    "download_extract('ml-1m', data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 先來看看數據 - 用戶數據， 電影數據，評分數據\n",
    "本項目使用的是MovieLens 1M 數據集，包含6000個用戶在近4000部電影上的1億條評論。\n",
    "\n",
    "數據集分為三個文件：用戶數據users.dat，電影數據movies.dat和評分數據ratings.dat。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用戶數據\n",
    "分別有用戶ID、性別、年齡、職業ID和郵編等字段。\n",
    "\n",
    "數據中的格式：UserID::Gender::Age::Occupation::Zip-code\n",
    "\n",
    "- Gender is denoted by a \"M\" for male and \"F\" for female\n",
    "- Age is chosen from the following ranges:\n",
    "\n",
    "\t*  1:  \"Under 18\"\n",
    "\t* 18:  \"18-24\"\n",
    "\t* 25:  \"25-34\"\n",
    "\t* 35:  \"35-44\"\n",
    "\t* 45:  \"45-49\"\n",
    "\t* 50:  \"50-55\"\n",
    "\t* 56:  \"56+\"\n",
    "\n",
    "- Occupation is chosen from the following choices:\n",
    "\n",
    "\t*  0:  \"other\" or not specified\n",
    "\t*  1:  \"academic/educator\"\n",
    "\t*  2:  \"artist\"\n",
    "\t*  3:  \"clerical/admin\"\n",
    "\t*  4:  \"college/grad student\"\n",
    "\t*  5:  \"customer service\"\n",
    "\t*  6:  \"doctor/health care\"\n",
    "\t*  7:  \"executive/managerial\"\n",
    "\t*  8:  \"farmer\"\n",
    "\t*  9:  \"homemaker\"\n",
    "\t* 10:  \"K-12 student\"\n",
    "\t* 11:  \"lawyer\"\n",
    "\t* 12:  \"programmer\"\n",
    "\t* 13:  \"retired\"\n",
    "\t* 14:  \"sales/marketing\"\n",
    "\t* 15:  \"scientist\"\n",
    "\t* 16:  \"self-employed\"\n",
    "\t* 17:  \"technician/engineer\"\n",
    "\t* 18:  \"tradesman/craftsman\"\n",
    "\t* 19:  \"unemployed\"\n",
    "\t* 20:  \"writer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T09:21:06.601919Z",
     "start_time": "2019-06-08T09:21:06.539419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>OccupationID</th>\n",
       "      <th>Zip-code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID Gender  Age  OccupationID Zip-code\n",
       "0       1      F    1            10    48067\n",
       "1       2      M   56            16    70072\n",
       "2       3      M   25            15    55117\n",
       "3       4      M   45             7    02460\n",
       "4       5      M   25            20    55455"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_title = ['UserID', 'Gender', 'Age', 'OccupationID', 'Zip-code']\n",
    "users = pd.read_csv('./ml-1m/users.dat', sep='::', header=None, names=users_title, engine = 'python')\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可以看出UserID、Gender、Age和Occupation都是類別字段，其中郵編字段是我們不使用的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T11:22:05.212892Z",
     "start_time": "2019-06-08T11:22:05.181637Z"
    }
   },
   "source": [
    "### 電影數據\n",
    "分別有電影ID、電影名和電影風格等字段。\n",
    "\n",
    "數據中的格式：MovieID::Title::Genres\n",
    "\n",
    "- Titles are identical to titles provided by the IMDB (including\n",
    "year of release)\n",
    "- Genres are pipe-separated and are selected from the following genres:\n",
    "\n",
    "\t* Action\n",
    "\t* Adventure\n",
    "\t* Animation\n",
    "\t* Children's\n",
    "\t* Comedy\n",
    "\t* Crime\n",
    "\t* Documentary\n",
    "\t* Drama\n",
    "\t* Fantasy\n",
    "\t* Film-Noir\n",
    "\t* Horror\n",
    "\t* Musical\n",
    "\t* Mystery\n",
    "\t* Romance\n",
    "\t* Sci-Fi\n",
    "\t* Thriller\n",
    "\t* War\n",
    "\t* Western"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T09:21:08.633170Z",
     "start_time": "2019-06-08T09:21:08.601918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieID                               Title                        Genres\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4        5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_title = ['MovieID', 'Title', 'Genres']\n",
    "movies = pd.read_csv('./ml-1m/movies.dat', sep='::', header=None, names=movies_title, engine = 'python')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MovieID是類別字段，Title是文本，Genres也是類別字段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評分數據\n",
    "分別有用戶ID、電影ID、評分和時間戳等字段。\n",
    "\n",
    "數據中的格式：UserID::MovieID::Rating::Timestamp\n",
    "\n",
    "- UserIDs range between 1 and 6040 \n",
    "- MovieIDs range between 1 and 3952\n",
    "- Ratings are made on a 5-star scale (whole-star ratings only)\n",
    "- Timestamp is represented in seconds since the epoch as returned by time(2)\n",
    "- Each user has at least 20 ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T09:21:15.742545Z",
     "start_time": "2019-06-08T09:21:10.898795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>timestamps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  timestamps\n",
       "0       1     1193       5   978300760\n",
       "1       1      661       3   978302109\n",
       "2       1      914       3   978301968\n",
       "3       1     3408       4   978300275\n",
       "4       1     2355       5   978824291"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_title = ['UserID','MovieID', 'Rating', 'timestamps']\n",
    "ratings = pd.read_csv('./ml-1m/ratings.dat', sep='::', header=None, names=ratings_title, engine = 'python')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 評分字段Rating就是我們要學習的targets，時間戳字段我們不使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料前處理 - 1\n",
    "\n",
    "USER的部分\n",
    "- UserID、Occupation和MovieID不用變。\n",
    "- Gender：‘F’和‘M’轉換成0和1。\n",
    "- Age：轉成7個連續數字0~6。\n",
    "\n",
    "電影的部分 - 實驗會分成加電影的資料跟沒有的結果。 因爲不確定電影名跟類別可以提高精度多少。\n",
    "- Genres：是分類字段，要轉成數字。首先將Genres中的類別轉成字符串到數字，之後把每個電影的Genres字段轉成數字列表（因為有些電影是多個Genres的組合）\n",
    "- Title：處理方式跟Genres字段一樣，首先創建文本到數字的字典，然後將Title中的描述轉成數字的列表。另外Title中的年份也需要去掉。\n",
    "- Genres和Title字段需要將長度統一，這樣在神經網絡中方便處理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T11:33:56.010431Z",
     "start_time": "2019-06-08T11:33:55.947978Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\n",
    "    #read User data\n",
    "    users_title = ['UserID', 'Gender', 'Age', 'JobID', 'Zip-code']\n",
    "    users = pd.read_table('./ml-1m/users.dat', sep='::', header=None, names=users_title, engine = 'python')\n",
    "    users = users.filter(regex='UserID|Gender|Age|JobID')\n",
    "    users_orig = users.values\n",
    "    #Change gender and age in User data\n",
    "    gender_map = {'F':0, 'M':1}\n",
    "    users['Gender'] = users['Gender'].map(gender_map)\n",
    "\n",
    "    age_map = {val:ii for ii,val in enumerate(set(users['Age']))}\n",
    "    users['Age'] = users['Age'].map(age_map)\n",
    "\n",
    "    #Read Movie\n",
    "    movies_title = ['MovieID', 'Title', 'Genres']\n",
    "    movies = pd.read_table('./ml-1m/movies.dat', sep='::', header=None, names=movies_title, engine = 'python')\n",
    "    movies_orig = movies.values\n",
    "    #remove year in Title\n",
    "    pattern = re.compile(r'^(.*)\\((\\d+)\\)$')\n",
    "\n",
    "    title_map = {val:pattern.match(val).group(1) for ii,val in enumerate(set(movies['Title']))}\n",
    "    movies['Title'] = movies['Title'].map(title_map)\n",
    "\n",
    "    #電影類型轉數字字典\n",
    "    genres_set = set()\n",
    "    for val in movies['Genres'].str.split('|'):\n",
    "        genres_set.update(val)\n",
    "\n",
    "    genres_set.add('<PAD>')\n",
    "    genres2int = {val:ii for ii, val in enumerate(genres_set)}\n",
    "\n",
    "    #將電影類型轉成等長數字列表，長度是18\n",
    "    genres_map = {val:[genres2int[row] for row in val.split('|')] for ii,val in enumerate(set(movies['Genres']))}\n",
    "\n",
    "    for key in genres_map:\n",
    "        for cnt in range(max(genres2int.values()) - len(genres_map[key])):\n",
    "            genres_map[key].insert(len(genres_map[key]) + cnt,genres2int['<PAD>'])\n",
    "    \n",
    "    movies['Genres'] = movies['Genres'].map(genres_map)\n",
    "\n",
    "    #電影Title轉數字字典\n",
    "    title_set = set()\n",
    "    for val in movies['Title'].str.split():\n",
    "        title_set.update(val)\n",
    "    \n",
    "    title_set.add('<PAD>')\n",
    "    title2int = {val:ii for ii, val in enumerate(title_set)}\n",
    "\n",
    "    #將電影Title轉成等長數字列表，長度是15\n",
    "    title_count = 15\n",
    "    title_map = {val:[title2int[row] for row in val.split()] for ii,val in enumerate(set(movies['Title']))}\n",
    "    \n",
    "    for key in title_map:\n",
    "        for cnt in range(title_count - len(title_map[key])):\n",
    "            title_map[key].insert(len(title_map[key]) + cnt,title2int['<PAD>'])\n",
    "    \n",
    "    movies['Title'] = movies['Title'].map(title_map)\n",
    "\n",
    "    #Read Ratings\n",
    "    ratings_title = ['UserID','MovieID', 'ratings', 'timestamps']\n",
    "    ratings = pd.read_table('./ml-1m/ratings.dat', sep='::', header=None, names=ratings_title, engine = 'python')\n",
    "    ratings = ratings.filter(regex='UserID|MovieID|ratings')\n",
    "\n",
    "    #Combine all data in to data variables\n",
    "    data = pd.merge(pd.merge(ratings, users), movies)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把處理好的資料讀進來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T11:40:43.325139Z",
     "start_time": "2019-06-08T11:40:38.340764Z"
    }
   },
   "outputs": [],
   "source": [
    "data= load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T11:40:44.450140Z",
     "start_time": "2019-06-08T11:40:44.387640Z"
    }
   },
   "outputs": [],
   "source": [
    "#只要使用前500名的資料\n",
    "data = data[data[\"UserID\"]<500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T11:36:15.528840Z",
     "start_time": "2019-06-08T11:36:15.497627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73770, 8)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T11:40:48.059513Z",
     "start_time": "2019-06-08T11:40:48.028264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>ratings</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>JobID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>[1851, 1878, 4754, 5135, 739, 5083, 927, 927, ...</td>\n",
       "      <td>[5, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>[1851, 1878, 4754, 5135, 739, 5083, 927, 927, ...</td>\n",
       "      <td>[5, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>[1851, 1878, 4754, 5135, 739, 5083, 927, 927, ...</td>\n",
       "      <td>[5, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>[1851, 1878, 4754, 5135, 739, 5083, 927, 927, ...</td>\n",
       "      <td>[5, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[1851, 1878, 4754, 5135, 739, 5083, 927, 927, ...</td>\n",
       "      <td>[5, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  ratings  Gender  Age  JobID  \\\n",
       "0       1     1193        5       0    0     10   \n",
       "1       2     1193        5       1    5     16   \n",
       "2      12     1193        4       1    6     12   \n",
       "3      15     1193        4       1    6      7   \n",
       "4      17     1193        5       1    3      1   \n",
       "\n",
       "                                               Title  \\\n",
       "0  [1851, 1878, 4754, 5135, 739, 5083, 927, 927, ...   \n",
       "1  [1851, 1878, 4754, 5135, 739, 5083, 927, 927, ...   \n",
       "2  [1851, 1878, 4754, 5135, 739, 5083, 927, 927, ...   \n",
       "3  [1851, 1878, 4754, 5135, 739, 5083, 927, 927, ...   \n",
       "4  [1851, 1878, 4754, 5135, 739, 5083, 927, 927, ...   \n",
       "\n",
       "                                              Genres  \n",
       "0  [5, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18...  \n",
       "1  [5, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18...  \n",
       "2  [5, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18...  \n",
       "3  [5, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18...  \n",
       "4  [5, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#看看資料張得如何\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料前處理 - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 爲了使用模型做出來結果 把series轉換成array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T11:40:50.606454Z",
     "start_time": "2019-06-08T11:40:50.575196Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\brent\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\user\\Anaconda3\\envs\\brent\\lib\\site-packages\\ipykernel\\__main__.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\user\\Anaconda3\\envs\\brent\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "label = data[\"ratings\"].as_matrix()\n",
    "title = data[\"Title\"].as_matrix()\n",
    "genres = data[\"Genres\"].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Title跟Genres維度太高 把它轉換成跟用戶資料的維度一樣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T11:40:55.387660Z",
     "start_time": "2019-06-08T11:40:55.059515Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    #print(type(title[i]))\n",
    "    title[i] = np.asarray(title[i])\n",
    "    genres[i] = np.asarray(genres[i])\n",
    "   #print(type(title[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 把data資料中的 ratings,Title,Genres去掉，之後放在 data1裏面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T11:44:25.777478Z",
     "start_time": "2019-06-08T11:44:25.746228Z"
    }
   },
   "outputs": [],
   "source": [
    "data1 = data.drop([\"ratings\",\"Title\",\"Genres\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 先把data1轉換成list 之後在下面再次轉換成Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T11:46:53.211032Z",
     "start_time": "2019-06-08T11:46:53.117302Z"
    }
   },
   "outputs": [],
   "source": [
    "data1 = data1.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 要使用包含電影的特徵的時候 使用以下的程式碼，因爲結果使用 用戶的特徵比較 包含電影的程式碼 注解起來。可是兩個狀況的數據仍然下面會比較<br>\n",
    "data_list = []<br>\n",
    "for i in range(len(data)):<br>\n",
    "    data_ = np.concatenate((data1[i], title[i], genres[i]))<br>\n",
    "    data_list.append(data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T11:51:05.319582Z",
     "start_time": "2019-06-08T11:51:05.303954Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_list = []\n",
    "# for i in range(len(data)):\n",
    "#     data_ = np.concatenate((data1[i], title[i], genres[i]))\n",
    "#     data_list.append(data_)\n",
    "data_list = data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 把我們用的data_list資料轉換成array 這樣才能丟進去模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T11:52:11.114014Z",
     "start_time": "2019-06-08T11:52:11.051442Z"
    }
   },
   "outputs": [],
   "source": [
    "data_array = np.array(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T11:52:24.853683Z",
     "start_time": "2019-06-08T11:52:24.838056Z"
    }
   },
   "outputs": [],
   "source": [
    "#data_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 開始使用模型看看精度會如何\n",
    "\n",
    "- 以下準確率以評分的差距 就是精度來比較\n",
    "\n",
    "- MSE跟MAE來比較精度，約接近 0 越好 在此資料MAE比較直觀的知道，預測的評分跟原本的評分具體的兩個數據的差距多少。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T11:57:20.250812Z",
     "start_time": "2019-06-08T11:57:20.203936Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_array, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **把資料給正規化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T11:57:33.360131Z",
     "start_time": "2019-06-08T11:57:33.297686Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\brent\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\user\\Anaconda3\\envs\\brent\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\user\\Anaconda3\\envs\\brent\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T10:23:53.157458Z",
     "start_time": "2019-06-08T10:23:53.126209Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(x_train, y_train)\n",
    "result = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T10:23:54.751210Z",
     "start_time": "2019-06-08T10:23:54.735584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1109963360784072\n",
      "0.9191402037585548\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "print(sqrt(mean_squared_error(result, y_test)))\n",
    "print(mean_absolute_error(result, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE : 1.110 <br>MAE : 0.919"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T09:54:22.082652Z",
     "start_time": "2019-06-08T09:54:22.066986Z"
    }
   },
   "outputs": [],
   "source": [
    "#把上面的結果移除掉\n",
    "#del x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T10:08:57.812557Z",
     "start_time": "2019-06-08T09:54:36.832651Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\brent\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1054977673959607\n",
      "0.8891158932545625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "clf  = SVR()\n",
    "reg = clf.fit(x_train, y_train)\n",
    "result = reg.predict(x_test)\n",
    "\n",
    "print(sqrt(mean_squared_error(result, y_test)))\n",
    "print(mean_absolute_error(result, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE : 1.105 <br>MAE : 0.889"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-08T09:17:38.494Z"
    }
   },
   "source": [
    "# Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 先建構使用的神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:24:45.795402Z",
     "start_time": "2019-06-08T12:24:45.670460Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Dropout\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(5,)))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用 MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:18:43.845931Z",
     "start_time": "2019-06-08T12:18:32.689682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47212 samples, validate on 11804 samples\n",
      "Epoch 1/1000\n",
      "47212/47212 [==============================] - ETA: 2:37 - loss: 10.31 - ETA: 16s - loss: 8.5754 - ETA: 8s - loss: 8.4394 - ETA: 5s - loss: 8.434 - ETA: 4s - loss: 8.366 - ETA: 3s - loss: 8.313 - ETA: 3s - loss: 8.270 - ETA: 2s - loss: 8.220 - ETA: 2s - loss: 8.204 - ETA: 2s - loss: 8.167 - ETA: 1s - loss: 8.161 - ETA: 1s - loss: 8.147 - ETA: 1s - loss: 8.155 - ETA: 1s - loss: 8.136 - ETA: 1s - loss: 8.144 - ETA: 1s - loss: 8.139 - ETA: 1s - loss: 8.137 - ETA: 0s - loss: 8.140 - ETA: 0s - loss: 8.134 - ETA: 0s - loss: 8.146 - ETA: 0s - loss: 8.130 - ETA: 0s - loss: 8.132 - ETA: 0s - loss: 8.140 - ETA: 0s - loss: 8.141 - ETA: 0s - loss: 8.145 - ETA: 0s - loss: 8.143 - 2s 51us/step - loss: 8.1432 - val_loss: 8.0591\n",
      "Epoch 2/1000\n",
      "47212/47212 [==============================] - ETA: 3s - loss: 8.265 - ETA: 1s - loss: 8.344 - ETA: 1s - loss: 8.205 - ETA: 1s - loss: 8.160 - ETA: 1s - loss: 8.165 - ETA: 1s - loss: 8.139 - ETA: 1s - loss: 8.122 - ETA: 1s - loss: 8.141 - ETA: 1s - loss: 8.165 - ETA: 1s - loss: 8.166 - ETA: 1s - loss: 8.151 - ETA: 0s - loss: 8.140 - ETA: 0s - loss: 8.142 - ETA: 0s - loss: 8.121 - ETA: 0s - loss: 8.131 - ETA: 0s - loss: 8.134 - ETA: 0s - loss: 8.130 - ETA: 0s - loss: 8.126 - ETA: 0s - loss: 8.118 - ETA: 0s - loss: 8.103 - ETA: 0s - loss: 8.110 - ETA: 0s - loss: 8.111 - ETA: 0s - loss: 8.113 - ETA: 0s - loss: 8.116 - ETA: 0s - loss: 8.116 - ETA: 0s - loss: 8.115 - ETA: 0s - loss: 8.117 - 2s 36us/step - loss: 8.1202 - val_loss: 8.0591\n",
      "Epoch 3/1000\n",
      "47212/47212 [==============================] - ETA: 3s - loss: 8.280 - ETA: 1s - loss: 8.002 - ETA: 0s - loss: 8.056 - ETA: 0s - loss: 8.046 - ETA: 0s - loss: 8.066 - ETA: 0s - loss: 8.049 - ETA: 0s - loss: 8.066 - ETA: 0s - loss: 8.064 - ETA: 0s - loss: 8.063 - ETA: 0s - loss: 8.062 - ETA: 0s - loss: 8.067 - ETA: 0s - loss: 8.075 - ETA: 0s - loss: 8.084 - ETA: 0s - loss: 8.097 - ETA: 0s - loss: 8.095 - ETA: 0s - loss: 8.120 - ETA: 0s - loss: 8.122 - ETA: 0s - loss: 8.114 - ETA: 0s - loss: 8.101 - ETA: 0s - loss: 8.104 - ETA: 0s - loss: 8.117 - 1s 30us/step - loss: 8.1202 - val_loss: 8.0591\n",
      "Epoch 4/1000\n",
      "47212/47212 [==============================] - ETA: 0s - loss: 7.885 - ETA: 1s - loss: 8.100 - ETA: 1s - loss: 8.112 - ETA: 1s - loss: 8.123 - ETA: 1s - loss: 8.086 - ETA: 1s - loss: 8.104 - ETA: 1s - loss: 8.110 - ETA: 1s - loss: 8.126 - ETA: 1s - loss: 8.118 - ETA: 1s - loss: 8.096 - ETA: 1s - loss: 8.088 - ETA: 0s - loss: 8.107 - ETA: 0s - loss: 8.095 - ETA: 0s - loss: 8.098 - ETA: 0s - loss: 8.102 - ETA: 0s - loss: 8.098 - ETA: 0s - loss: 8.101 - ETA: 0s - loss: 8.112 - ETA: 0s - loss: 8.106 - ETA: 0s - loss: 8.114 - ETA: 0s - loss: 8.122 - ETA: 0s - loss: 8.123 - ETA: 0s - loss: 8.125 - ETA: 0s - loss: 8.125 - ETA: 0s - loss: 8.124 - ETA: 0s - loss: 8.117 - 2s 36us/step - loss: 8.1202 - val_loss: 8.0591\n",
      "Epoch 5/1000\n",
      "47212/47212 [==============================] - ETA: 3s - loss: 8.240 - ETA: 1s - loss: 8.222 - ETA: 1s - loss: 8.218 - ETA: 1s - loss: 8.257 - ETA: 1s - loss: 8.241 - ETA: 1s - loss: 8.262 - ETA: 1s - loss: 8.244 - ETA: 1s - loss: 8.210 - ETA: 1s - loss: 8.193 - ETA: 1s - loss: 8.171 - ETA: 1s - loss: 8.166 - ETA: 0s - loss: 8.152 - ETA: 0s - loss: 8.155 - ETA: 0s - loss: 8.161 - ETA: 0s - loss: 8.164 - ETA: 0s - loss: 8.148 - ETA: 0s - loss: 8.139 - ETA: 0s - loss: 8.125 - ETA: 0s - loss: 8.121 - ETA: 0s - loss: 8.126 - ETA: 0s - loss: 8.131 - ETA: 0s - loss: 8.130 - ETA: 0s - loss: 8.130 - ETA: 0s - loss: 8.131 - ETA: 0s - loss: 8.132 - ETA: 0s - loss: 8.126 - ETA: 0s - loss: 8.124 - 2s 38us/step - loss: 8.1202 - val_loss: 8.0591\n",
      "Epoch 6/1000\n",
      "47212/47212 [==============================] - ETA: 3s - loss: 8.225 - ETA: 1s - loss: 8.151 - ETA: 1s - loss: 8.192 - ETA: 1s - loss: 8.165 - ETA: 1s - loss: 8.181 - ETA: 1s - loss: 8.137 - ETA: 1s - loss: 8.166 - ETA: 1s - loss: 8.164 - ETA: 1s - loss: 8.149 - ETA: 1s - loss: 8.163 - ETA: 1s - loss: 8.165 - ETA: 0s - loss: 8.159 - ETA: 0s - loss: 8.155 - ETA: 0s - loss: 8.151 - ETA: 0s - loss: 8.145 - ETA: 0s - loss: 8.142 - ETA: 0s - loss: 8.146 - ETA: 0s - loss: 8.147 - ETA: 0s - loss: 8.144 - ETA: 0s - loss: 8.146 - ETA: 0s - loss: 8.139 - ETA: 0s - loss: 8.131 - ETA: 0s - loss: 8.127 - ETA: 0s - loss: 8.126 - ETA: 0s - loss: 8.116 - ETA: 0s - loss: 8.118 - 2s 37us/step - loss: 8.1202 - val_loss: 8.0591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2adef810b00>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = optimizers.Adam(lr=1e-3) \n",
    "earlystop = EarlyStopping(monitor = 'val_loss',patience=5)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "model.fit(x_train,y_train,epochs=1000, batch_size=200,validation_split=0.2,callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:18:46.642807Z",
     "start_time": "2019-06-08T12:18:45.892810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14754/14754 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 50us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.841576332354263"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = model.evaluate(x_test,y_test)\n",
    "#開開根號\n",
    "sqrt(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MSE的精度為 2.841**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用 MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:19:18.247822Z",
     "start_time": "2019-06-08T12:19:18.232197Z"
    }
   },
   "outputs": [],
   "source": [
    "#移除上面的 MSE模型\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:26:57.693375Z",
     "start_time": "2019-06-08T12:26:50.630934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47212 samples, validate on 11804 samples\n",
      "Epoch 1/1000\n",
      "47212/47212 [==============================] - ETA: 2:19 - loss: 2.745 - ETA: 10s - loss: 2.608 - ETA: 5s - loss: 2.6072 - ETA: 3s - loss: 2.616 - ETA: 2s - loss: 2.619 - ETA: 1s - loss: 2.619 - ETA: 1s - loss: 2.617 - ETA: 1s - loss: 2.620 - ETA: 1s - loss: 2.620 - ETA: 0s - loss: 2.620 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.625 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.625 - ETA: 0s - loss: 2.622 - 2s 35us/step - loss: 2.6235 - val_loss: 2.6142\n",
      "Epoch 2/1000\n",
      "47212/47212 [==============================] - ETA: 0s - loss: 2.695 - ETA: 0s - loss: 2.642 - ETA: 0s - loss: 2.626 - ETA: 0s - loss: 2.626 - ETA: 0s - loss: 2.628 - ETA: 0s - loss: 2.629 - ETA: 0s - loss: 2.628 - ETA: 0s - loss: 2.629 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.625 - 1s 21us/step - loss: 2.6235 - val_loss: 2.6142\n",
      "Epoch 3/1000\n",
      "47212/47212 [==============================] - ETA: 3s - loss: 2.745 - ETA: 1s - loss: 2.651 - ETA: 0s - loss: 2.641 - ETA: 0s - loss: 2.633 - ETA: 0s - loss: 2.624 - ETA: 0s - loss: 2.623 - ETA: 0s - loss: 2.625 - ETA: 0s - loss: 2.620 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.617 - ETA: 0s - loss: 2.618 - ETA: 0s - loss: 2.618 - ETA: 0s - loss: 2.618 - ETA: 0s - loss: 2.622 - 1s 21us/step - loss: 2.6235 - val_loss: 2.6142\n",
      "Epoch 4/1000\n",
      "47212/47212 [==============================] - ETA: 0s - loss: 2.615 - ETA: 0s - loss: 2.649 - ETA: 0s - loss: 2.651 - ETA: 0s - loss: 2.628 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.620 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.620 - ETA: 0s - loss: 2.625 - ETA: 0s - loss: 2.627 - ETA: 0s - loss: 2.625 - ETA: 0s - loss: 2.626 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.622 - 1s 22us/step - loss: 2.6235 - val_loss: 2.6142\n",
      "Epoch 5/1000\n",
      "47212/47212 [==============================] - ETA: 3s - loss: 2.525 - ETA: 1s - loss: 2.590 - ETA: 1s - loss: 2.594 - ETA: 1s - loss: 2.611 - ETA: 0s - loss: 2.609 - ETA: 0s - loss: 2.612 - ETA: 0s - loss: 2.615 - ETA: 0s - loss: 2.614 - ETA: 0s - loss: 2.616 - ETA: 0s - loss: 2.616 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.622 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.624 - 1s 22us/step - loss: 2.6235 - val_loss: 2.6142\n",
      "Epoch 6/1000\n",
      "47212/47212 [==============================] - ETA: 3s - loss: 2.640 - ETA: 1s - loss: 2.582 - ETA: 0s - loss: 2.603 - ETA: 0s - loss: 2.612 - ETA: 0s - loss: 2.612 - ETA: 0s - loss: 2.615 - ETA: 0s - loss: 2.618 - ETA: 0s - loss: 2.617 - ETA: 0s - loss: 2.620 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.619 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.621 - ETA: 0s - loss: 2.621 - 1s 21us/step - loss: 2.6235 - val_loss: 2.6142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2adeff0ea58>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#先再次執行 上面 “先建構使用的神經網路”的部分\n",
    "opt = optimizers.Adam(lr=1e-3) \n",
    "earlystop = EarlyStopping(monitor = 'val_loss',patience=5)\n",
    "model.compile(loss='mean_absolute_error', optimizer=opt)\n",
    "model.fit(x_train,y_train,epochs=1000, batch_size=200,validation_split=0.2,callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:30:06.831125Z",
     "start_time": "2019-06-08T12:30:06.081122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14754/14754 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 50us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.6143418733902672"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = model.evaluate(x_test,y_test)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:27:20.120250Z",
     "start_time": "2019-06-08T12:27:20.088999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6168926598232387"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAE的精度為 1.616**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 結論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 跑過有正規化跟沒有正規化的結果，發現對此資料沒有什麽大的差別，還是這研究仍然使用有正規化的方法\n",
    "- 一開始因爲不知道哪一個特徵好用，所以全部用進來之後，電影特徵 “title, Genres”移除之後，只用5個特徵的時候得到稍微比較好的結果，差別都是0.0001左右的範圍内。\n",
    "- 電影的特徵 Title及Genres，這兩個包含的内容共結果比較模糊 沒有幫助於得到更好的精度\n",
    "- DNN結果爲什麽比SVM,LR差呢？<br>- 目標是一個人對每個電影的評分。 可是電影的種類太多，這樣對DNN來講， 資料量相對小。 因爲不可能資料裏面都有每個人對每個電影的評分， 而且有些人不會認真去評分。所以結果反而使用傳統機器學習方法的時候結果比較好。\n",
    "* 使用方法的比較圖如下<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " +| LR| SVR | DNN\n",
    "-----|-----|--|---\n",
    "MAE|0.92|0.85|1.61\n",
    "MSE|1.11|1.10|2.84\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:brent]",
   "language": "python",
   "name": "conda-env-brent-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
